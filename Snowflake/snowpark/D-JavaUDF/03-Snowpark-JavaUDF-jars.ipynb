{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment UDF\n",
    "\n",
    "Sentiment analysis, or the ability to understand the general postive or negative connotation of free form text, can play an important part in understanding what your customers (and critics) are saying about you.  In this exercise, we will create a JavaUDF that will use an existing open source library [Stanford CoreNLP](https://stanfordnlp.github.io/CoreNLP/) to analyze the sentiment of text in Snowflake.\n",
    "\n",
    "We are going to leverage the ability to create JavaUDFs that utilize multiple .jars (aka, libraries), not just those we authored. Along with this we will employ more intricate code that uses these libraries to perform sentiment analysis inside of Snowflake.\n",
    "\n",
    "- [ ] Review the .scala code, built using SBT and packaged to a jar file\n",
    "- [ ] Upload our custom .jar\n",
    "- [ ] Create a function using our jar, and extra libraries\n",
    "- [ ] Test our sentiment analysis using ANALYZE_TEXT\n",
    "\n",
    "![](../assets/java_sent_overview.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.snowflake.snowpark._\n",
    "import com.snowflake.snowpark.functions._\n",
    "import com.snowflake.snowpark.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Set connection properties built in de_snowpark/A-Dataframes/01-Sessions.ipynb\n",
    "val pwd = sys.env.get(\"PWD\").fold(\"\")(_.toString)\n",
    "val filename = s\"$pwd/de_snowpark/connect.properties\"\n",
    "\n",
    "val session = Session.builder.configFile(s\"$filename\").create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a Snowflake internal stage that will be used by our Java UDFs\n",
    "session.sql(\"create stage if not exists raw.JAVA_UDF_STAGE\").collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Scala Code\n",
    "\n",
    "Here is the code that has been written and compiled for you, to perform the sentiment anaysis...\n",
    "\n",
    "\n",
    "```scala\n",
    "import java.util.Properties // for initializing StanfordCoreNLP\n",
    " \n",
    "// Import StanfordCoreNLP\n",
    "import edu.stanford.nlp.ling.CoreAnnotations\n",
    "import edu.stanford.nlp.neural.rnn.RNNCoreAnnotations\n",
    "import edu.stanford.nlp.pipeline.{Annotation, StanfordCoreNLP}\n",
    "import edu.stanford.nlp.sentiment.SentimentCoreAnnotations\n",
    "\n",
    "// Misc for building our result\n",
    "import scala.collection.convert.wrapAll._\n",
    "import scala.collection.mutable.ListBuffer\n",
    "\n",
    "// Scala class\n",
    "class SentimentAnalyzer {\n",
    "\n",
    "    // Initialize our processor, and load our model ONCE during the constructor\n",
    "    val props = new Properties()\n",
    "    props.setProperty(\"annotators\", \"tokenize, ssplit, parse, sentiment\")\n",
    "    val pipeline: StanfordCoreNLP = new StanfordCoreNLP(props)\n",
    "\n",
    "    // This public method is called with every UDF invocation\n",
    "    def analyzeSentence (s: String) : String = { \n",
    "\n",
    "        val processed = pipeline.process(s)\n",
    "        val sentences = processed.get(classOf[CoreAnnotations.SentencesAnnotation])\n",
    "        \n",
    "        // TODO need to check empty!\n",
    "        val numberSentences = sentences.size\n",
    "         \n",
    "        var sentimentScores : ListBuffer[Int] = ListBuffer()\n",
    "        sentences.map(sentence => {\n",
    "            var tree = sentence.get(classOf[SentimentCoreAnnotations.SentimentAnnotatedTree])\n",
    "            var sentiment = RNNCoreAnnotations.getPredictedClass(tree)\n",
    "            sentimentScores.append(sentiment)\n",
    "        })\n",
    "        \n",
    "        val totalSentimentScore = sentimentScores.sum        \n",
    "        val averageSentiment = totalSentimentScore / numberSentences\n",
    "        val sentimentString = sentimentScores.mkString(\",\")\n",
    "        \n",
    "        // We create a JSON string, which Snowflake will parse as VARIANT\n",
    "        var myJson = raw\"\"\"{\"AVERAGE_SENTIMENT\" : ${averageSentiment},\"NUMBER_SENTENCES\" : ${numberSentences}, \"SENTIMENTS\" : [${sentimentString}]}\"\"\"\n",
    "\n",
    "        // return\n",
    "        myJson\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "This jar has already been assembled, using `sbt` build tool and is called `edu-sentiment-udf_2.12-1.0.jar`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress: Check\n",
    "\n",
    "- [X] Review the .scala code, built using SBT and packaged to a jar file\n",
    "- [ ] Upload our custom .jar\n",
    "- [ ] Create a function using our jar, and extra libraries\n",
    "- [ ] Test our sentiment analysis using ANALYZE_TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the Custom Jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.file.put(\n",
    "    \"edu-sentiment-udf_2.12-1.0.jar\", \"@raw.JAVA_UDF_STAGE\",\n",
    "     Map(\n",
    "        \"OVERWRITE\" -> \"true\"\n",
    "        , \"AUTO_COMPRESS\" -> \"false\"\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress: Check\n",
    "\n",
    "- [X] Review the .scala code, built using SBT and packaged to a jar file\n",
    "- [X] Upload our custom .jar\n",
    "- [ ] Create a function using our jar, and extra libraries\n",
    "- [ ] Test our sentiment analysis using ANALYZE_TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Function (Using Extra Jars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"\"\"\n",
    "\n",
    "CREATE FUNCTION raw.ANALYZE_TEXT(arg1 STRING) \n",
    "RETURNS VARIANT \n",
    "LANGUAGE JAVA IMPORTS = (\n",
    "'@training_db.traininglab.datasets_stage/dependencies/javax.json.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/istack-commons-runtime-3.0.7.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/jaxb-impl-2.4.0-b180830.0438.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/stanford-corenlp-4.2.2-javadoc.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/jaxb-api-2.4.0-b180830.0359.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/protobuf-java-3.11.4.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/stanford-corenlp-4.2.2.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/ejml-simple-0.39.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/xom.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/ejml-core-0.39.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/stanford-corenlp-4.2.2-models.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/slf4j-simple.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/javax.activation-api-1.2.0.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/jollyday.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/ejml-ddense-0.39.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/joda-time.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/slf4j-api.jar'\n",
    ",'@training_db.traininglab.datasets_stage/dependencies/scala-library-2.12.11.jar'\n",
    ",'@raw.JAVA_UDF_STAGE/edu-sentiment-udf_2.12-1.0.jar'\n",
    ") HANDLER='SentimentAnalyzer.analyzeSentence';\n",
    "\n",
    "\"\"\").collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress: Check\n",
    "\n",
    "- [X] Review the .scala code, built using SBT and packaged to a jar file\n",
    "- [X] Upload our custom .jar\n",
    "- [X] Create a function using our jar, and extra libraries\n",
    "- [ ] Test our sentiment analysis using ANALYZE_TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Sentiment Analysis Running in Snowflake\n",
    "\n",
    "Now let's pass in some example text and invoke the sentiment analysis processing using our ANALYZE_TEXT UDF in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val exampleSentencesDF = session.createDataFrame(Seq(\n",
    "    (\"This is great!  I definitely hated this thing!\"), (\"This is AWFUL!!!\")\n",
    ")).toDF(\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleSentencesDF\n",
    "    .withColumn(\"SENTIMENT\", callUDF(\"raw.ANALYZE_TEXT\", col(\"input\"))) \n",
    ".show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress: Check\n",
    "\n",
    "- [X] Review the .scala code, built using SBT and packaged to a jar file\n",
    "- [X] Upload our custom .jar\n",
    "- [X] Create a function using our jar, and extra libraries\n",
    "- [X] Test our sentiment analysis using ANALYZE_TEXT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Snowpark (Scala 2.12)",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
