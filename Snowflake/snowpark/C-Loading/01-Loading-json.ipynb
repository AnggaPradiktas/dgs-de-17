{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa4c4a7-a551-4c66-8775-d64329acaeb5",
   "metadata": {},
   "source": [
    "# Snowpark Loading JSON Data\n",
    "\n",
    "In this lab you will perform the following:\n",
    "\n",
    "- [ ] Upload a JSON file to a Snowflake internal stage\n",
    "- [ ] Build a DataFrame that reads data from the JSON file\n",
    "- [ ] Load the entire JSON file to a table\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fcfd8-70cc-45c3-a99f-f35aa45101ec",
   "metadata": {},
   "source": [
    "## Create a Session\n",
    "\n",
    "Create a Snowpark Session by passing in the connection properties file created in the [first lab exercise](../A-Dataframes/01-Sessions.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf2acc-cf91-460b-8332-36efe3fa1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.snowflake.snowpark._\n",
    "import com.snowflake.snowpark.functions._\n",
    "import com.snowflake.snowpark.types._\n",
    "\n",
    "// Set connection properties file variable\n",
    "val pwd = sys.env.get(\"PWD\").fold(\"\")(_.toString)\n",
    "val filename = s\"$pwd/de_snowpark/connect.properties\"\n",
    "\n",
    "val session = Session.builder.configFile(s\"$filename\").create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6928437f-e2a9-415f-ba7f-eee66861efca",
   "metadata": {},
   "source": [
    "---\n",
    "## Put simple.json File\n",
    "\n",
    "In this section you will use the `file` convenience method of the Session object, to return a FileOperation object, which has access to `PUT`/`GET` data from Snowflake internal stages.  \n",
    "\n",
    "Before calling `file.put()`, let's create a set of options to override the default values.  \n",
    "\n",
    "In our case below, we want the `PUT` command to upload a file without automatically GZIPing it by setting the AUTO_COMPRESS to FALSE, and to OVERWRITE the file if it already exists.  \n",
    "\n",
    "Run the `PUT` to upload the local `simple.json` file specified by `localFileName` to your user stage `@~` specified as the `stageLocation` along with the specified options in `putOptions`.\n",
    "\n",
    "See [PUT command](https://docs.snowflake.com/en/sql-reference/sql/put.html) for the full list of options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb97d5-7e89-41e2-8b29-b26d196b5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "val putOptions = Map(\"AUTO_COMPRESS\" -> \"FALSE\", \"OVERWRITE\"->\"TRUE\")\n",
    "val localFileName = \"./simple.json\"\n",
    "val stageLocation = \"@~\"\n",
    "\n",
    "session.file.put(localFileName, stageLocation, putOptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d3f24-7c4e-4564-bc60-28c000f13954",
   "metadata": {},
   "source": [
    "---\n",
    "### Progress: Check\n",
    "\n",
    "- [X] Upload the JSON file to a Snowflake internal stage\n",
    "- [ ] Build a DataFrame that can read the data from the JSON file\n",
    "- [ ] Load the entire JSON file to a table\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa17e66-53ae-4132-80ef-c363c1bddfa9",
   "metadata": {},
   "source": [
    "## Build a DataFrame to Read the File Data\n",
    "\n",
    "The Session object has a `read` method that can be used to load data in various supported formats, with definition of format-specific options, from a Snowflake stage to a DataFrame.  \n",
    "\n",
    "Run the `json` function to upload JSON files in the stage specified by `jsonFilePath` and set the JSON file format option with the `options` method, to strip any outer array specified in the `readOptions` configuration passed in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384beaef-c70d-4f61-a075-235d3ccd4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "val jsonFilePath = \"@~/simple.json\"\n",
    "val readOptions = Map(\"STRIP_OUTER_ARRAY\" -> \"TRUE\")\n",
    "\n",
    "val dfRawJson = session.read\n",
    "                       .options(readOptions)\n",
    "                       .json(jsonFilePath)\n",
    "\n",
    "\n",
    "dfRawJson.show\n",
    "dfRawJson.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f619d958-b96f-49cf-b621-4ce8a637aa70",
   "metadata": {},
   "source": [
    "Examine the output of the `show` and `count` methods. We can now access and see values in the `simple.json` file from a DataFrame. \n",
    "\n",
    "Use the the `schema` method to see the definition of the columns of this DataFrame as a result of calling `.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0abe03-6c7f-4c0d-9069-f6578db6c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRawJson.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee8c34-a7d1-4098-84d2-4ad1d136200d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> For files in formats other than CSV, like JSON, the DataFrameReader object treats the data in the file as a single VARIANT column with the name $1.</div>\n",
    "\n",
    "---\n",
    "### Progress: Check\n",
    "\n",
    "- [X] Upload the JSON file to a Snowflake internal stage\n",
    "- [X] Build a DataFrame that can read the data from the JSON file\n",
    "- [ ] Load the entire JSON file to a table\n",
    "---\n",
    "\n",
    "## Load to a table\n",
    "\n",
    "Using the DataFrame above, let's load a table with the contents of the file.\n",
    "\n",
    "Since `$1` is not a valid column name we will need use the `as` function to rename the DataFrame column. Note that the `as`, `alias` and `name` functions are equivalent, and can be used to return a new renamed column.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e58191f-c6fd-4ed0-b82c-e2753f021d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val df = dfRawJson.select(col(\"$1\").as(\"JSON\"))\n",
    "                  .write.saveAsTable(\"raw.SIMPLE_JSON\")\n",
    "\n",
    "var tableRows = session.table(\"raw.SIMPLE_JSON\").count()\n",
    "println(s\"The table raw.SIMPLE_JSON has $tableRows rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee0f85-5c0e-4674-9822-b186576d1a65",
   "metadata": {},
   "source": [
    "---\n",
    "### Progress: Check\n",
    "\n",
    "- [X] Upload the JSON file to a Snowflake internal stage\n",
    "- [X] Build a DataFrame that can read the data from the JSON file\n",
    "- [X] Load the entire JSON file to a table\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Snowpark (Scala 2.12)",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
