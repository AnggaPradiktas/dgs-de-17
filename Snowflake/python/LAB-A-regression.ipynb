{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Lab\n",
    "\n",
    "Someone from your Data Science group has been creating a regression to predict, and fit a line, to the average arrival delays to each airport.\n",
    "\n",
    "Currently, they:\n",
    "1. Extract the flight data from their source system (using CSV)\n",
    "1. In their notebook load, parse the data and convert to datatypes\n",
    "1. Sample 20000 flights randomly in memory (this has been known to exhaust memory on their machine)\n",
    "1. Calculate average delays into a particular airport\n",
    "1. Use a regression to fit a line to predict what the average delay is for a given month\n",
    "1. Upload to an internal system for use by other analysts\n",
    "\n",
    "Now that our historical flight data is centrally located and loaded, we're going to *replace steps 1-4 above* with a single SQL query to Snowflake and let them focus on what they enjoy most about their jobs... fitting models, and doing their detailed statistical and machine learning algorithims!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Snowflake\n",
    "\n",
    "Using the credentials for our class:\n",
    "* `snowflake_account` : `sfeducationalservices1_acct982` or similar\n",
    "* `snowflake_user` : `mongoose` (or whatever your animal is!)\n",
    "* `snowflake_password` : `EasyToGuess123!` or whatever password you have set for your user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from urllib.parse import quote\n",
    "\n",
    "## Get snowflake Account name (no .snowflakecomputing.com)\n",
    "print(\"Snowflake Account:\")\n",
    "snowflake_account = input()\n",
    "print(\"Snowflake Username:\")\n",
    "snowflake_user = input()\n",
    "snowflake_password = quote(getpass.getpass(\"Snowflake Password:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Alchemy\n",
    "\n",
    "In this example, we are going to use a couple of convenience packages to connect to Snowflake. Of course, we can connect directly via `.conn()`, but for now let's use the helpful `%sql` commands and connect via `SQLAlchemy` to make getting the Data Scientist data straightforward.\n",
    "\n",
    "A SQLAlchemy URL has some specific formatting requirements, some of which are for all SQLAlchemy dialects (i.e., to other databases) and some are specific to Snowflake's Python connector.  You can read more about the SQLAlchemy connector here:\n",
    "\n",
    "* [SQLAlchemy URL docs](https://docs.sqlalchemy.org/en/13/core/engines.html#database-urls)\n",
    "* [Snowflake SQLAlchemy Connection instructions](https://docs.snowflake.com/en/user-guide/sqlalchemy.html#snowflake-specific-parameters-and-behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used by the SQL magic commands below!  SQLAlchemy!\n",
    "database_url = f\"snowflake://{snowflake_user}:{snowflake_password}@{snowflake_account}/{snowflake_user}_DB?warehouse={snowflake_user}_WH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Snowflake\n",
    "\n",
    "We're all setup and ready to connect to Snowflake.  Now we will use the magic command `%sql` which is a convenience for executing sql statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connecting to Snowflake via SQLAlchemy\n",
    "%load_ext sql\n",
    "%sql $database_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the connection\n",
    "\n",
    "Next, let's just do the Snowflake equivalent of `HELLO WORLD!`\n",
    "\n",
    "We'll issue a trivial call, that executes in all security roles, contexts, and without warehouses running, to test to ensure we're connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select current_date();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set warehouse size\n",
    "\n",
    "Now we will set a query tag and our warehouse size before executing any queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "alter session set query_tag='({snowflake_user}) Lab - SCENARIO: Connectors for Data Science Workloads';\n",
    "alter warehouse {snowflake_user}_WH set warehouse_size = 'xsmall';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Data Scientists want to sample, randomly, 1000 rows from all flights.  We'll use a SQL statement that grabs data from our `RAW` table and samples randomly 1000 rows for a single destination `SEA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql result_set << \n",
    "select \n",
    "    month\n",
    "    , nvl(arr_delay, 0) as avg_delay\n",
    "from raw.ONTIME_REPORTING SAMPLE (1000 rows)\n",
    "where \n",
    "DEST ='SEA';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = result_set.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our 1000 randomly sampled rows available for use in our regression.  Let's take a quick look, to better understand the data.  Let's just take a quick peek and plot it on a scatter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy has a very particular Array format that it likes for operations.  Let's get the dataset oriented (rows to columns) to ensure the array is ready for NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_numpy = df.to_numpy().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure we have the correct datatypes, let's let NumPy know that our months (1..12) are INTs and that our delays are FLOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array(result_numpy[0]).astype(int)\n",
    "xy = np.array(result_numpy[1]).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Data Scientists have done this fitting before; they use the NumPy polynomial fitting to make a reasonable guess as to the delay for a particular month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trend = np.polyfit(xs,xy,5)\n",
    "trendpoly = np.poly1d(trend)\n",
    "\n",
    "plt.plot(xs,xy,'o')\n",
    "plt.plot(np.unique(xs),trendpoly(np.unique(xs)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You should see a plot of the line, and the estimated values for the delay by month!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_estimate = trendpoly(np.unique(xs))\n",
    "monthly_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowflake, our cloud data platform, is the centralized location for where this information, and the outcome of our Data Scientists' work, will be.  \n",
    "\n",
    "We will take our data, and push it up to Snowflake into a table in our `MODELED` zone for downstream consumption by other applications and dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data = np.array ([['SEA','SEA','SEA','SEA','SEA','SEA','SEA','SEA','SEA','SEA','SEA','SEA']\n",
    "             ,np.unique(xs)\n",
    "             ,monthly_estimate]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_snowflake = regression_data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"sea_regression_data.csv\", for_snowflake, delimiter=',', fmt='%s', comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql use schema modeled;\n",
    "%sql PUT file://./sea_regression_data.csv @~;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql copy into estimated_delays from @~/sea_regression_data.csv.gz purge=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from modeled.estimated_delays;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql alter session unset query_tag;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
